# Вычислительная Линейная Алгебра: 


Этот проект содержит реализации методов прикладной линейной алгебры

Каждое задание реализовано в отдельном Python файле (`taskN.py`).
## Оглавление

- [Задания](#задания)
  - [Задание 1: PA=LU разложение и решение СЛАУ (`task1.py`)](#задание-1-palu-разложение-и-решение-слау-task1py)
  - [Задание 2: Нахождение обратной матрицы через PA=LU (`task2.py`)](#задание-2-нахождение-обратной-матрицы-через-palu-task2py)
  - [Задание 3: LDLT разложение и проверка положительной определенности (`task3.py`)](#задание-3-ldlt-разложение-и-проверка-положительной-определенности-task3py)
  - [Задание 4: Разложение Холецкого и решение СЛАУ (`task4.py`)](#задание-4-разложение-холецкого-и-решение-слау-task4py)
  - [Задание 5: LDLT для трехдиагональной матрицы и решение СЛАУ (`task5.py`)](#задание-5-ldlt-для-трехдиагональной-матрицы-и-решение-слау-task5py)
  - [Задание 6: QR разложение (Хаусхолдер) и МНК (`task6.py`)](#задание-6-qr-разложение-хаусхолдер-и-мнк-task6py)
- [Инструкция по запуску](#Инструкция-по-запуску)
- [Зависимости](#зависимости)
## Задания

---

### Задание 1: PA=LU разложение и решение СЛАУ (`task1.py`)

**Задание:**
> 1. Реализовать разложение Гаусса $PA = LU$ (с выбором ведущего элемента). использовать его для решения линейной системы $Ax = b$. Организовать проверку, вычислив $A\hat{x} - b$, где $\hat{x}$ – найденное решение.

**Теоретическая Часть:**

Используется **метод Гаусса с выбором ведущего элемента по столбцу**.Мы ищем на каждом шаге $k$ максимальный по модулю элемент в $k$-м столбце ниже или на диагонали и меняем текущую строку $k$ с той строкой, где найден этот элемент. Эти перестановки строк можно представить с помощью **матрицы перестановок P**. 
В результате  получаем разложение **PA=LU**, где:
*   $P$ - матрица перестановок (получается из единичной матрицы применением тех же перестановок строк)
*   $L$ - нижняя треугольная матрица с единицами на главной диагонали
*   $U$ - верхняя треугольная матрица

1.  Исходная система: $Ax = b$
2.  Умножаем слева на $P$: $PAx = Pb$
3.  Подставляем $PA=LU$: $LUx = Pb$
4.  Вводим вспомогательный вектор $y = Ux$. Система распадается на две:
    *   $Ly = Pb$ (Решается **прямой подстановкой**)
    *   $Ux = y$ (Решается **обратной подстановкой**)

**Формулы:**

1.  **Разложение:**
    $$ PA = LU $$

2.  **Решение $Ly=c$ (где $c = Pb$), прямая подстановка:**
    $L$ - нижняя треугольная, $L\_{ii}=1$.
    $$ y\_0 = c\_0 $$
    $$ y\_i = c\_i - \sum\_{j=0}^{i-1} L\_{ij} y\_j \quad (\text{для } i=1, \dots, n-1) $$

3.  **Решение $Ux=y$, обратная подстановка:**
    $U$ - верхняя треугольная.
    $$ x\_{n-1} = \frac{y\_{n-1}}{U\_{n-1, n-1}} $$
    $$ x\_i = \frac{1}{U\_{ii}} \left( y\_i - \sum\_{j=i+1}^{n-1} U\_{ij} x\_j \right) \quad (\text{для } i=n-2, \dots, 0) $$

4.  **Проверка:**
    Вычисляется вектор невязки $r = A\hat{x} - b$

**Примеры:**

*   **Встроенный пример (`e`):**
    *   $A = \begin{bmatrix} 0 & 1 & 1 \\ 2 & 1 & -1 \\ -1 & 1 & -2 \end{bmatrix}, \quad b = \begin{bmatrix} 2 \\ 1 \\ -5 \end{bmatrix}$
    *   Ожидаемое решение: $\hat{x} \approx \begin{bmatrix} 1.375 \\ 0.125 \\ 1.875 \end{bmatrix}$
    *   Ожидаемая невязка: $r\approx \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}$
*   **Пример для ручного ввода (`m`):**
    *   $n=2$
    *   Матрица A:
        ```
        Строка 1: 1 1
        Строка 2: 1 -1
        ```
    *   Вектор b: `5 1`
    *   Ожидаемое решение: $\hat{x} = \begin{bmatrix} 3 \\ 2 \end{bmatrix}$
    *   Ожидаемая невязка: $\begin{bmatrix} 0 \\ 0 \end{bmatrix}$


---

### Задание 2: Нахождение обратной матрицы через PA=LU (`task2.py`)

**Задание:**
> 2. Реализовать разложение Гаусса $PA = LU$ (с выбором ведущего элемента), использовать его для нахождения обратной матрицы $A^{-1}$. Организовать проверку, вычислив $A \hat{A}^{-1}$, где $\hat{A}^{-1}$ – найденная обратная матрица.

**Теоретическая Часть:**

Обратная матрица $A^{-1}$ определяется уравнением $A A^{-1} = I$
Обозначим столбцы $A^{-1}$ как $x\_1, x\_2, \dots, x\_n$, а столбцы $I$ как $e\_1, e\_2, \dots, e\_n$ 
Тогда  $A [x\_1 | \dots | x\_n] = [e\_1 | \dots | e\_n]$. 
Это эквивалентно $n$ независимым системам линейных уравнений:
$$ Ax\_i = e\_i, \quad i=1, \dots, n $$
Для нахождения $A^{-1}$  используется разложение $PA=LU$ из Задания 1.
Разложение $PA=LU$ выполняется только один раз.
Для каждого столбца $e\_i$:
1.  Вычисляется $c\_i = P e\_i$.
2.  Решается $L y\_i = c\_i$ (прямая подстановка).
3.  Решается $U x\_i = y\_i$ (обратная подстановка).
Вектор $x\_i$ является $i$-м столбцом искомой обратной матрицы $A^{-1}$: 
 $A^{-1} = [x\_1 | x\_2 | \dots | x\_n]$
Проверка: Вычисляется $A \hat{A}^{-1}$. В идеальном случае результат $\approx I$.

**Примеры:**

*   **Встроенный пример (`e`):**
    *   $A = \begin{bmatrix} 1 & 2 & 0 \\ 2 & 5 & 1 \\ 0 & 1 & 3 \end{bmatrix}$
    *   Ожидаем обратную матрицу: $\hat{A}^{-1} \approx \begin{bmatrix} 14 & -6 & 2 \\ -6 & 3 & -1 \\ 2 & -1 & 1 \end{bmatrix}$
    *   Проверка: $A \hat{A}^{-1} \approx \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$
*   **Пример для ручного ввода (`m`):**
    *   $n=2$
    *   Матрица A:
        ```
        Строка 1: 1 1
        Строка 2: 1 -1
        ```
    *   Ожидаем обратную матрицу: $\hat{A}^{-1} = \begin{bmatrix} 0.5 & 0.5 \\ 0.5 & -0.5 \end{bmatrix}$
    *   Проверка: $A \hat{A}^{-1} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$



---

### Задание 3: LDLT разложение и проверка положительной определенности (`task3.py`)

**Задание:**
> 3. Реализовать $LDL^T$-разложение матрицы A, использовать его для проверки положительной определенности матрицы.

**Теоретическая Часть:**

$LDL^T$-разложение применимо к **симметричным** матрицам $A$ ($A=A^T$):
$$ A = L D L^T $$
где:
*   $L$ - **нижняя треугольная матрица с единицами** на главной диагонали ($L\_{ii}=1$, $L\_{ij}=0$ при $j>i$).
*   $D$ - **диагональная матрица** ($D\_{ij}=0$ при $i \neq j$), $d\_k = D\_{kk}$.


Симметричная матрица $A$ является **положительно определенной**, если $x^T A x > 0$ для любого ненулевого вектора $x$. Симметричная матрица $A$ положительно определена **тогда и только тогда, когда все диагональные элементы $d_k$ в ее $LDL^T$-разложении строго положительны ($d\_k > 0$)**.
В алгоритме последовательно вычисляются элементы  $D$ и $L$ и проверяется знак диагональных элементов $d\_k$


**Формулы:**

Выводятся из равенства $A\_{ij} = (LDL^T)\_{ij} = \sum\_{k=0}^{\min(i,j)} L\_{ik} L\_{jk} d\_k$:

1.  **Элементы диагональной матрицы D ($d\_j = D\_{jj}$):**
    Приравнивая $A\_{jj} = \sum\_{k=0}^{j} L\_{jk}^2 d\_k = (\sum\_{k=0}^{j-1} L\_{jk}^2 d\_k) + L\_{jj}^2 d\_j$ и учитывая $L\_{jj}=1$:
    $$ d\_j = A\_{jj} - \sum\_{k=0}^{j-1} L\_{jk}^2 d\_k $$

2.  **Элементы матрицы L ниже диагонали ($L\_{ij}$ для $i > j$):**
    Приравнивая $A\_{ij} = \sum\_{k=0}^{j} L\_{ik} L\_{jk} d\_k = (\sum\_{k=0}^{j-1} L\_{ik} L\_{jk} d\_k) + L\_{ij} L\_{jj} d\_j$ и учитывая $L\_{jj}=1$:
    $$ L\_{ij} = \frac{1}{d\_j} \left( A\_{ij} - \sum\_{k=0}^{j-1} L\_{ik} d\_k L\_{jk} \right) $$
    (нужно $d\_j \neq 0$ для вычисления $L\_{ij}$)

3.  **Критерий положительной определенности:** $A$ положительно определена $\iff$ все $d\_j > 0$ (на практике $d\_j > \epsilon > 0$).

**Примеры:**

*   **Встроенные примеры (`t`):**
    *   *Положительно определенная:*
        $A = \begin{bmatrix} 4 & 12 & -16 \\ 12 & 37 & -43 \\ -16 & -43 & 98 \end{bmatrix}$
        Ожидаемый результат: Матрица положительно определена (все $d\_i > 0$).
    *   *Не положительно определенная:*
        $A = \begin{bmatrix} 1 & 2 & 3 \\ 2 & 1 & 2 \\ 3 & 2 & 1 \end{bmatrix}$
        Ожидаемый результат: Матрица не положительно определена (найдется $d\_i \le 0$).
*   **Пример для ручного ввода (`m`):**
    *   $n=2$
    *   Матрица A:
        ```
        Строка 1: 2 1
        Строка 2: 1 2
        ```
    *   Ожидаемый результат: $d\_0=2, L\_{10}=1/2=0.5, d\_1 = 2 - 0.5^2 \cdot 2 = 1.5$. 
    *  $d\_i > 0$  $\implies$ Матрица положительно определена.



---

### Задание 4: Разложение Холецкого и решение СЛАУ (`task4.py`)

**Задание:**
> 4. Реализовать разложение Холецкого для симметричной, положительно определенной матрицы A, использовать его для решения линейной системы $Ax = b$ (если A не является положительно определенной, алгоритм останавливается). Организовать проверку, вычислив $A\hat{x} - b$, где $\hat{x}$ – найденное решение.

**Теоретическая Часть:**

Разложение Холецкого применимо **только к симметричным положительно определенным (СПО)** матрицам $A$ :
$$ A = L L^T $$
где $L$ - **нижняя треугольная матрица** (не обязательно 1 на диагонали)

Для решения системы $Ax=b$ (где $A$ - СПО) с помощью $A=LL^T$:
1.  Подставляем: $LL^T x = b$.
2.  Вводим $y = L^T x$.
3.  Решаем две треугольные системы:
    *   $Ly = b$ (прямая подстановка)
    *   $L^T x = y$ (обратная подстановка)

**Формулы:**

Из равенства $A\_{ij} = (LL^T)\_{ij} = \sum\_{k=0}^{\min(i,j)} L\_{ik} L\_{jk}$:

1.  **Диагональные элементы $L\_{jj}$:**
    Из $A\_{jj} = \sum\_{k=0}^{j} L\_{jk}^2 = (\sum\_{k=0}^{j-1} L\_{jk}^2) + L\_{jj}^2$:
    $$ L\_{jj} = \sqrt{A\_{jj} - \sum\_{k=0}^{j-1} L\_{jk}^2} $$
    *Проверка СПО:* Выражение под корнем $A\_{jj} - \sum\_{k=0}^{j-1} L\_{jk}^2$ **должно быть $> 0$**.

2.  **Элементы $L\_{ij}$ ниже диагонали ($i > j$):**
    Из $A\_{ij} = \sum\_{k=0}^{j} L\_{ik} L\_{jk} = (\sum\_{k=0}^{j-1} L\_{ik} L\_{jk}) + L\_{ij} L\_{jj}$:
    $$ L\_{ij} = \frac{1}{L\_{jj}} \left( A\_{ij} - \sum\_{k=0}^{j-1} L\_{ik} L\_{jk} \right) $$

3.  **Решение $Ly = b$ (прямая подстановка):**
    $$ y\_0 = b\_0 / L\_{00} $$
    $$ y\_i = \frac{1}{L\_{ii}} \left( b\_i - \sum\_{k=0}^{i-1} L\_{ik} y\_k \right) \quad (\text{для } i=1, \dots, n-1) $$

4.  **Решение $L^T x = y$ (обратная подстановка):**
    $U = L^T$ (верхняя треугольная).
    $$ x\_{n-1} = y\_{n-1} / U\_{n-1, n-1} = y\_{n-1} / L\_{n-1, n-1} $$
    $$ x\_i = \frac{1}{U\_{ii}} \left( y\_i - \sum\_{k=i+1}^{n-1} U\_{ik} x\_k \right) = \frac{1}{L\_{ii}} \left( y\_i - \sum\_{k=i+1}^{n-1} L\_{ki} x\_k \right) \quad (\text{для } i=n-2, \dots, 0) $$

**Примеры:**


*   **Встроенные примеры (`t`):**
    *    Симметричная положительно определенная матрица.
        *   $A = \begin{bmatrix} 4. & 12. & -16. \\ 12. & 37. & -43. \\ -16. & -43. & 98. \end{bmatrix}, \quad b = \begin{bmatrix} 1. \\ 2. \\ 3. \end{bmatrix}$
    *   Симметричная, но не положительно определенная матрица
        *   $A = \begin{bmatrix} 1. & 2. & 3. \\ 2. & 1. & 2. \\ 3. & 2. & 1. \end{bmatrix}, \quad b = \begin{bmatrix} 1. \\ 1. \\ 1. \end{bmatrix}$

*   **Пример для ручного ввода (`m`):**
    *   $n=2$
    *   Матрица A:
        ```
        Строка 1: 4 2
        Строка 2: 2 5
        ```
    *   Вектор b: `6 7`
    *   Ожидаемый результат:
         $L = \begin{bmatrix} 2. & 0. \\ 1. & 2. \end{bmatrix}$ , $\hat{x} = \begin{bmatrix} 1. \\ 1. \end{bmatrix}$.
        $A\hat{x} - b = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$



---

### Задание 5: LDLT для трехдиагональной матрицы и решение СЛАУ (`task5.py`)

**Задание:**
> 5. Реализовать $LDL^T$-разложение симметричной трехдиагональной матрицы A. В случае, когда A положительно определена, использовать разложение для решения линейной системы $Ax=b$. Организовать проверку, вычислив $A\hat{x} - b$, где $\hat{x}$ – найденное решение.

**Теоретическая Часть:**

Аналогично Заданию 3, но для **симметричных трехдиагональных матриц**. 
*   Матрица $A$: главная диагональ $a\_i$, под- и наддиагональ $c\_i$.
*   Матрица $L$: единицы на главной диагонали, под-диагональ $l\_i$.
*   Матрица $D$: диагональные элементы $d\_i$.

Разложение $A = LDL^T$ и решение $Ax=b$ выполняются в лгоритме за $O(n)$. 
Проверка на положительную определенность : $d\_i > 0$ для любого $i$.

**Формулы (для трехдиагонального случая):**

1.  **Разложение $A = LDL^T$:**
    $$ d\_0 = a\_0 $$
    Для $i=1, \dots, n-1$:
    $$ l\_i = c\_i / d\_{i-1} \quad (= A\_{i, i-1} / d\_{i-1}) $$
    $$ d\_i = a\_i - l\_i^2 d\_{i-1} \quad (= A\_{ii} - L\_{i, i-1}^2 d\_{i-1}) $$
    *Проверка ПО:* $d\_i > 0$ для всех $i$.

2.  **Решение $Ly=b$:**
    $$ y\_0 = b\_0 $$
    $$ y\_i = b\_i - l\_i y\_{i-1} \quad (\text{для } i=1, \dots, n-1) $$

3.  **Решение $Dz=y$:**
    $$ z\_i = y\_i / d\_i \quad (\text{для } i=0, \dots, n-1) $$

4.  **Решение $L^T x = z$:**
    $$ x\_{n-1} = z\_{n-1} $$
    $$ x\_i = z\_i - l\_{i+1} x\_{i+1} \quad (\text{для } i=n-2, \dots, 0) $$

**Примеры:**

*   **Встроенный пример (`t`):**
* *Положительно определенная $(n=5)$:*
    *   Главная диагональ $A$: `[2.0, 2.0, 2.0, 2.0, 2.0]`
    *   Под-диагональ $A$: `[-1.0, -1.0, -1.0, -1.0]`
    *   Вектор $b$: `[1.0, 2.0, 3.0, 4.0, 5.0]`
    *  $$A = \begin{bmatrix} 2 & -1 & 0 & 0 & 0 \\ -1 & 2 & -1 & 0 & 0 \\ 0 & -1 & 2 & -1 & 0 \\ 0 & 0 & -1 & 2 & -1 \\ 0 & 0 & 0 & -1 & 2 \end{bmatrix}$$
    *   Ожидаемый результат: Матрица положительно определена, разложение.

* *Не положительно определенная $(n=4)$:* * 
* Главная диагональ $A$ (`a1_i`): `[1.0, 1.0, 1.0, 1.0]`  
* Под-диагональ $A$ (`c1_i`): `[1.0, 1.0, 1.0]` 
 * Вектор $b$ (`b1_i`): `[1.0, 2.0, 3.0, 4.0]`
 $$ A = \begin{bmatrix} 1 & 1 & 0 & 0 \\ 1 & 1 & 1 & 0 \\ 0 & 1 & 1 & 1 \\ 0 & 0 & 1 & 1 \end{bmatrix} $$
 
 * Ожидаемый результат:  ($d\_3 \le 0$). Матрица не положительно определена. Разложение остановится. Решение системы этим методом невозможно.



*   **Пример для ручного ввода (`m`):**
    *   $n=3$
    *   Главная диагональ A: `2 -1 2`
    *   Под-диагональ A: `-1 1`
    *   Вектор b: `1 0 2`
    *   Ожидаемый результат:
        *   $d\_0=2$
        *   $l\_1 = -1/2 = -0.5$, $d\_1 = -1 - (-0.5)^2 \cdot 2 = -1.5$. **Матрица не положительно определена.** Разложение остановится. Решение системы этим методом невозможно.



---

### Задание 6: QR разложение (Хаусхолдер) и МНК (`task6.py`)

**Текст Задания:**
> 6. Реализовать $QR$-разложение при помощи отражений Хаусхолдера для прямоугольной матрицы полного столбцевого ранга. Решить задачу наименьших квадратов на основе полученного разложения.

**Теоретическая Часть:**

QR-разложение представляет прямоугольную матрицу $A$ ($m \times n$, $m \ge n$) как произведение ортогональной матрицы $Q$ ($m \times m$) и верхней трапециевидной матрицы $R$ ($m \times n$):
$$ A = QR $$
где $Q^T Q = I\_m$ и $R = \begin{bmatrix} R\_{\text{hat}} \\ 0 \end{bmatrix}$ ($R\_{\text{hat}}$ - верхняя треугольная $n \times n$).

Методом Хаусхолдера строится матрица $R$ путем последовательного применения ортогональных матриц отражения $H\_k$: $R = H\_n \dots H\_1 A$. Матрица $Q^T = H\_n \dots H\_1$.
Полное создание $Q$ не требуется для МНК.

**Отражение Хаусхолдера:** Для обнуления элементов под диагональю в $k$-м столбце текущей матрицы $A'$ используется матрица $H\_k = I - \beta\_k v\_k v\_k^T$.
*   В подстолбеце $x = A'_{k:m, k}$.
*   Вычисляем $\alpha = \text{copysign}(||x||\_2, x\_0)$.
*    $v\_k = x + \alpha e\_1$ (для подпространства).
*   $\beta\_k = 2 / (v\_k^T v\_k)$.
Применение отражения к матрице $C$(текущая матрица $R$, при $k=0, C=A$) и вектору $c$ :
$$ H\_k C = C - \beta\_k v\_k (v\_k^T C) $$
$$ H\_k c = c - \beta\_k v\_k (v\_k^T c) $$
$R = H\_n \dots H\_1 A$, $c = H\_n \dots H\_1 b$

**Задача наименьших квадратов (МНК):** Минимизировать $||Ax - b||\_2$.
Используя QR: $||Ax - b||\_2 = ||QRx - b||\_2 = ||Rx - Q^T b||\_2$.
Обозначим $c = Q^T b$. Минимизируем $||Rx - c||\_2$.
$$ ||Rx - c||\_2^2 = || \begin{bmatrix} R\_{\text{hat}} \\ 0 \end{bmatrix} x - \begin{bmatrix} c\_1 \\ c\_2 \end{bmatrix} ||\_2^2 = ||R\_{\text{hat}}x - c\_1||\_2^2 + ||c\_2||\_2^2 $$
Минимум достигается при $R\_{\text{hat}}x - c\_1 = 0$.

 $R\_{\text{hat}} x = c\_1$

**Алгоритм МНК через QR:**
1.  Применить отражения Хаусхолдера $H\_1, \dots, H\_n$ к $A$ и $b$ одновременно, чтобы получить $R = H\_n \dots H\_1 A$ и $c = H\_n \dots H\_1 b$.
2.  Выделить верхнюю квадратную часть $R\_{\text{hat}} = R[0:n, 0:n]$ и первые $n$ компонент $c\_1 = c[0:n]$.
3.  Решить верхнетреугольную систему $R\_{\text{hat}} x = c\_1$ с помощью обратной подстановки.



**Примеры:**

*   **Встроенный пример (`e`):**
    *   $A = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \\ 1 & 4 \end{bmatrix}, \quad b = \begin{bmatrix} 1 \\ 2 \\ 2 \\ 3 \end{bmatrix}$
    *   Ожидаемое МНК решение: $\hat{x} \approx \begin{bmatrix} 0.5 \\ 0.6 \end{bmatrix}$
    *   Ожидаемая норма невязки: $\approx 0.447$
*   **Пример для ручного ввода (`m`):**
    *   $m=3, n=2$
    *   Матрица A:
        ```
        Строка 1: 1 0
        Строка 2: 0 1
        Строка 3: 1 1
        ```
    *   Вектор b: `1 1 3`
    *   Ожидаемое МНК решение: $\hat{x} \approx \begin{bmatrix} 1.333 \\ 1.333 \end{bmatrix}$
    *   Ожидаемая норма невязки: $\approx 0.577$



---

## Инструкция по запуску


1.  **Задание 1 (PA=LU и решение Ax=b):**
    ```bash
    python task1.py
    ```
    Выберите режим: `e` для встроенного примера или `m` для ручного ввода матрицы $A$ и вектора $b$. Выведет разложение P, L, U, решение $x$ и проверку невязки.

2.  **Задание 2 (Обратная матрица через PA=LU):**
    ```bash
    python task2.py
    ```
    Выберите режим: `e` для встроенного примера или `m` для ручного ввода матрицы $A$. Выведет найденную обратную матрицу $\hat{A}^{-1}$ и проверку $A\hat{A}^{-1}$.

3.  **Задание 3 (LDLT и проверка положительной определенности):**
    ```bash
    python task3.py
    ```
    Выберите режим: `t` для запуска тестов на нескольких примерах или `m` для ручного ввода матрицы $A$. Выведет результат проверки на положительную определенность и само $LDL^T$ разложение (если возможно).

4.  **Задание 4 (Разложение Холецкого и решение Ax=b):**
    ```bash
    python task4.py
    ```
    Выберите режим: `t` для запуска тестов на примерах или `m` для ручного ввода матрицы $A$ и вектора $b$. Выведет разложение Холецкого $L$ (если возможно), решение $x$ и проверку невязки.

5.  **Задание 5 (LDLT для трехдиагональной и решение Ax=b):**
    ```bash
    python task5.py
    ```
    Выберите режим: `t` для запуска тестов на примерах или `m` для ручного ввода диагоналей трехдиагональной матрицы $A$ и вектора $b$. Выведет $LDL^T$ разложение (векторы $l\_i$ и $d\_i$), решение $x$ и проверку невязки.

6.  **Задание 6 (QR Хаусхолдера и МНК):**
    ```bash
    python task6.py
    ```
    Выберите режим: `e` для встроенного примера или `m` для ручного ввода *прямоугольной* матрицы $A$ и вектора $b$. Выведет МНК-решение $x$ и проверку невязки $b - A\hat{x}$.

## Зависимости

*   **Python 3.x**
*   **NumPy:** 
    ```bash
    pip install numpy
    ```
